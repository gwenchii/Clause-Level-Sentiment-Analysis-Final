{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56438240",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858a6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv(csv_file_path):\n",
    "    print(f\"Loading data from {csv_file_path}...\")\n",
    "\n",
    "    df = pd.read_csv(\n",
    "        csv_file_path,\n",
    "        skiprows=2,\n",
    "        header=0,\n",
    "        names=[\"Tweet Number\", \"Clause Number\", \"Clause\", \"Final Sentiment\"]\n",
    "    )\n",
    "    print(\"Columns found:\", df.columns.tolist())\n",
    "    print(df.head(5))  # Show first 5 rows for debugging\n",
    "\n",
    "    print(\"Rows before cleaning:\", len(df))\n",
    "    missing_clause = df['Clause'].isna().sum()\n",
    "    missing_sentiment = df['Final Sentiment'].isna().sum()\n",
    "    print(f\"Rows with missing Clause: {missing_clause}\")\n",
    "    print(f\"Rows with missing Final Sentiment: {missing_sentiment}\")\n",
    "\n",
    "    df = df.dropna(subset=['Clause', 'Final Sentiment'])\n",
    "    print(\"Rows after cleaning:\", len(df))\n",
    "\n",
    "    df['Clause'] = df['Clause'].astype(str).str.strip()\n",
    "    df['Final Sentiment'] = df['Final Sentiment'].astype(str).str.strip().str.lower()\n",
    "\n",
    "    print(f\"ðŸ“Š Loaded {len(df)} clauses from {df['Tweet Number'].nunique()} tweets\")\n",
    "    print(\"Sentiment distribution:\", df['Final Sentiment'].value_counts().to_dict())\n",
    "\n",
    "    tweet_data = []\n",
    "    for tweet_num, tweet_group in df.groupby('Tweet Number'):\n",
    "        clauses = []\n",
    "        tweet_group = tweet_group.sort_values('Clause Number')\n",
    "        for _, row in tweet_group.iterrows():\n",
    "            clauses.append({\n",
    "                'clause_text': row['Clause'],\n",
    "                'sentiment': row['Final Sentiment']\n",
    "            })\n",
    "        tweet_data.append({\n",
    "            'tweet_id': tweet_num,\n",
    "            'clauses': clauses\n",
    "        })\n",
    "\n",
    "    print(f\"Data conversion completed: {len(tweet_data)} tweets ready for training\")\n",
    "    return tweet_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109abcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaglishSentimentAnalyzer:\n",
    "    def __init__(self, vectorizer=None, model=None,\n",
    "                 max_features=30000, \n",
    "                 ngram_range=(1, 2),\n",
    "                 alpha=0.1,\n",
    "                 pos_threshold=0.2,\n",
    "                 neg_threshold=-0.2):\n",
    "        \n",
    "        self.max_features = max_features\n",
    "        self.ngram_range = ngram_range\n",
    "        self.alpha = alpha\n",
    "        self.pos_threshold = pos_threshold\n",
    "        self.neg_threshold = neg_threshold\n",
    "        self.vectorizer = vectorizer\n",
    "        self.model = model\n",
    "\n",
    "        self.class_weights = None\n",
    "        self.classes = None\n",
    "        self.is_fitted = False\n",
    "\n",
    "        self.training_history = {}\n",
    "\n",
    "    def predict(self, text):\n",
    "        X = self.vectorizer.transform([text])\n",
    "        prediction = self.model.predict(X)[0]\n",
    "        probs = self.model.predict_proba(X)[0]\n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"prediction\": prediction,\n",
    "            \"probabilities\": dict(zip(self.model.classes_, probs))\n",
    "        }\n",
    "        \n",
    "    def _setup_vectorizer(self):\n",
    "        \"\"\"Setup TF-IDF vectorizer for Taglish text\"\"\"\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=self.max_features,\n",
    "            ngram_range=self.ngram_range,\n",
    "            lowercase=True,\n",
    "            strip_accents='unicode',\n",
    "            stop_words=None,\n",
    "            min_df=1,\n",
    "            max_df=0.95,\n",
    "            sublinear_tf=True,\n",
    "            norm='l2'\n",
    "        )\n",
    "        \n",
    "    def _setup_model(self):\n",
    "        \"\"\"Setup Multinomial Naive Bayes model\"\"\"\n",
    "        self.model = MultinomialNB(\n",
    "            alpha=self.alpha,\n",
    "            fit_prior=True\n",
    "        )\n",
    "        \n",
    "    def _compute_class_weights(self, y):\n",
    "\n",
    "        self.classes = np.unique(y)\n",
    "        class_weights = compute_class_weight('balanced', classes=self.classes, y=y)\n",
    "        self.class_weights = dict(zip(self.classes, class_weights))\n",
    "        return self.class_weights\n",
    "    \n",
    "    \n",
    "        \n",
    "    def prepare_data(self, tweet_data):\n",
    "        clause_data = []\n",
    "        \n",
    "        for tweet in tweet_data:\n",
    "            tweet_id = tweet['tweet_id']\n",
    "            for clause_idx, clause in enumerate(tweet['clauses']):\n",
    "                clause_data.append({\n",
    "                    'tweet_id': tweet_id,\n",
    "                    'clause_idx': clause_idx,\n",
    "                    'clause_text': clause['clause_text'],\n",
    "                    'sentiment': clause['sentiment']\n",
    "                })\n",
    "        \n",
    "        return pd.DataFrame(clause_data)\n",
    "    \n",
    "    def predict_text(self, text):\n",
    "        if not self.is_fitted:\n",
    "            raise ValueError(\"Model is not trained yet. Please train or load a model first.\")\n",
    "    \n",
    "        # Transform input into TF-IDF features\n",
    "        X = self.vectorizer.transform([text])\n",
    "    \n",
    "        # Predict class\n",
    "        prediction = self.model.predict(X)[0]\n",
    "    \n",
    "        # Predict probabilities\n",
    "        probs = self.model.predict_proba(X)[0]\n",
    "        prob_dict = dict(zip(self.model.classes_, probs))\n",
    "    \n",
    "        return {\n",
    "            \"text\": text,\n",
    "            \"prediction\": prediction,\n",
    "            \"probabilities\": prob_dict\n",
    "     }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7aae0e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(self, tweet_data, cv_folds=10, cv_repeats=3, verbose=True):\n",
    "    \"\"\"Train the sentiment analysis model with cross-validation\"\"\"\n",
    "    if verbose:\n",
    "        print(\"Starting Taglish Sentiment Model Training...\")\n",
    "        \n",
    "    #Prepare clause-level data\n",
    "    clause_df = self.prepare_data(tweet_data)\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Prepared {len(clause_df)} clauses from {len(tweet_data)} tweets\")\n",
    "        print(\"Class distribution:\", Counter(clause_df['sentiment']))\n",
    "    \n",
    "    #Setup components\n",
    "    self._setup_vectorizer()\n",
    "    self._setup_model()\n",
    "    \n",
    "    #Extract features and labels\n",
    "    X_text = clause_df['clause_text'].tolist()\n",
    "    y = clause_df['sentiment'].values\n",
    "    \n",
    "    #Fit vectorizer and transform data\n",
    "    if verbose:\n",
    "        print(\"ðŸ”§ Fitting TF-IDF vectorizer...\")\n",
    "    X = self.vectorizer.fit_transform(X_text)\n",
    "    \n",
    "    #Compute class weights\n",
    "    self.class_weights = self._compute_class_weights(y)\n",
    "    if verbose:\n",
    "        print(\"Class weights:\", self.class_weights)\n",
    "    \n",
    "    #Cross-validation\n",
    "    cv = RepeatedStratifiedKFold(n_splits=cv_folds, n_repeats=cv_repeats, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    all_predictions = []\n",
    "    all_true_labels = []\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Starting {cv_folds}-fold CV with {cv_repeats} repeats...\")\n",
    "    \n",
    "    for fold_idx, (train_idx, test_idx) in enumerate(cv.split(X, y)):\n",
    "        if verbose and fold_idx % 5 == 0:\n",
    "            print(f\"   Processing fold {fold_idx + 1}/{cv_folds * cv_repeats}\")\n",
    "        \n",
    "        #Split data\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        \n",
    "        #Create model for this fold\n",
    "        fold_model = MultinomialNB(alpha=self.alpha, fit_prior=True)\n",
    "        \n",
    "        #Apply class weights through sample weights\n",
    "        sample_weights = np.array([self.class_weights[label] for label in y_train])\n",
    "        fold_model.fit(X_train, y_train, sample_weight=sample_weights)\n",
    "        \n",
    "        #Predict\n",
    "        y_pred = fold_model.predict(X_test)\n",
    "        \n",
    "        #Calculate metrics\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            y_test, y_pred, average='weighted', zero_division=0\n",
    "        )\n",
    "        \n",
    "        fold_results.append({\n",
    "            'fold': fold_idx + 1,\n",
    "            'accuracy': accuracy,\n",
    "            'precision': precision,\n",
    "            'recall': recall,\n",
    "            'f1': f1\n",
    "        })\n",
    "        \n",
    "        all_predictions.extend(y_pred)\n",
    "        all_true_labels.extend(y_test)\n",
    "    \n",
    "    #Calculate final metrics\n",
    "    results_df = pd.DataFrame(fold_results)\n",
    "    \n",
    "    self.training_history = {\n",
    "        'cv_results': results_df,\n",
    "        'mean_accuracy': results_df['accuracy'].mean(),\n",
    "        'std_accuracy': results_df['accuracy'].std(),\n",
    "        'mean_precision': results_df['precision'].mean(),\n",
    "        'std_precision': results_df['precision'].std(),\n",
    "        'mean_recall': results_df['recall'].mean(),\n",
    "         'std_recall': results_df['recall'].std(),\n",
    "        'mean_f1': results_df['f1'].mean(),\n",
    "        'std_f1': results_df['f1'].std(),\n",
    "        'classification_report': classification_report(all_true_labels, all_predictions, zero_division=0),\n",
    "        'class_distribution': Counter(y),\n",
    "        'n_features': X.shape[1],\n",
    "        'n_samples': X.shape[0]\n",
    "    }\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"\\nCross-Validation Results:\")\n",
    "        print(f\"   Accuracy:  {self.training_history['mean_accuracy']:.4f} Â± {self.training_history['std_accuracy']:.4f}\")\n",
    "        print(f\"   Precision: {self.training_history['mean_precision']:.4f} Â± {self.training_history['std_precision']:.4f}\")\n",
    "        print(f\"   Recall:    {self.training_history['mean_recall']:.4f} Â± {self.training_history['std_recall']:.4f}\")\n",
    "        print(f\"   F1-Score:  {self.training_history['mean_f1']:.4f} Â± {self.training_history['std_f1']:.4f}\")\n",
    "    \n",
    "    #Train final model on all data\n",
    "    if verbose:\n",
    "        print(\"Training final model on complete dataset...\")\n",
    "    \n",
    "    sample_weights = np.array([self.class_weights[label] for label in y])\n",
    "    self.model.fit(X, y, sample_weight=sample_weights)\n",
    "    self.is_fitted = True\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Model training completed!\")\n",
    "    \n",
    "    return self.training_history\n",
    "\n",
    "TaglishSentimentAnalyzer.train = train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce126c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_clause_sentiment(self, clause_text):\n",
    "    \"\"\"Predict sentiment for a single clause\"\"\"\n",
    "    if not self.is_fitted:\n",
    "        raise ValueError(\"Model must be trained before making predictions\")\n",
    "    \n",
    "    if isinstance(clause_text, str):\n",
    "        clause_text = [clause_text]\n",
    "    \n",
    "    # Vectorize\n",
    "    X = self.vectorizer.transform(clause_text)\n",
    "    \n",
    "    # Predict\n",
    "    prediction = self.model.predict(X)[0]\n",
    "    probabilities = self.model.predict_proba(X)[0]\n",
    "    confidence = np.max(probabilities)\n",
    "    \n",
    "    return prediction, confidence\n",
    "\n",
    "def predict_tweet_sentiment(self, tweet_clauses):\n",
    "    \"\"\"Predict sentiment for a complete tweet using clause aggregation\"\"\"\n",
    "    if not self.is_fitted:\n",
    "        raise ValueError(\"Model must be trained before making predictions\")\n",
    "    \n",
    "    # Vectorize clauses\n",
    "    clause_vectors = self.vectorizer.transform(tweet_clauses)\n",
    "\n",
    "    # Get clause-level predictions and probabilities\n",
    "    clause_predictions = self.model.predict(clause_vectors)\n",
    "    clause_probabilities = self.model.predict_proba(clause_vectors)\n",
    "    \n",
    "    # Calculate TF-IDF weights for each clause\n",
    "    clause_tfidf_weights = np.array(clause_vectors.sum(axis=1)).flatten()\n",
    "    \n",
    "    if clause_tfidf_weights.sum() > 0:\n",
    "        clause_tfidf_weights = clause_tfidf_weights / clause_tfidf_weights.sum()\n",
    "    else:\n",
    "        clause_tfidf_weights = np.ones(len(tweet_clauses)) / len(tweet_clauses)\n",
    "    \n",
    "    # Weighted average of probabilities\n",
    "    weighted_probs = np.average(clause_probabilities, weights=clause_tfidf_weights, axis=0)\n",
    "    \n",
    "    # Convert to sentiment score\n",
    "    class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
    "    \n",
    "    if 'positive' in class_to_idx and 'negative' in class_to_idx:\n",
    "        pos_idx = class_to_idx['positive']\n",
    "        neg_idx = class_to_idx['negative']\n",
    "        sentiment_score = weighted_probs[pos_idx] - weighted_probs[neg_idx]\n",
    "    else:\n",
    "        sentiment_score = 0.0\n",
    "    \n",
    "    # Apply threshold rules\n",
    "    if sentiment_score >= self.pos_threshold:\n",
    "        tweet_sentiment = 'positive'\n",
    "    elif sentiment_score <= self.neg_threshold:\n",
    "        tweet_sentiment = 'negative'\n",
    "    else:\n",
    "        tweet_sentiment = 'neutral'\n",
    "    \n",
    "    return tweet_sentiment, sentiment_score, clause_predictions.tolist()\n",
    "\n",
    "# Add prediction methods to the class\n",
    "TaglishSentimentAnalyzer.predict_clause_sentiment = predict_clause_sentiment\n",
    "TaglishSentimentAnalyzer.predict_tweet_sentiment = predict_tweet_sentiment\n",
    "\n",
    "print(\"Prediction methods added to class!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "435db3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(self, filepath='models\\taglish_sentiment_model.pkl'):\n",
    "    \"\"\"Save the complete trained model to a pickle file\"\"\"\n",
    "    if not self.is_fitted:\n",
    "        raise ValueError(\"Model must be trained before saving\")\n",
    "    \n",
    "    model_data = {\n",
    "        'vectorizer': self.vectorizer,\n",
    "        'model': self.model,\n",
    "        'class_weights': self.class_weights,\n",
    "        'classes': self.classes,\n",
    "        'parameters': {\n",
    "            'max_features': self.max_features,\n",
    "            'ngram_range': self.ngram_range,\n",
    "            'alpha': self.alpha,\n",
    "            'pos_threshold': self.pos_threshold,\n",
    "            'neg_threshold': self.neg_threshold\n",
    "        },\n",
    "        'training_history': self.training_history,\n",
    "        'is_fitted': self.is_fitted\n",
    "    }\n",
    "    \n",
    "    with open(filepath, 'wb') as f:\n",
    "        pickle.dump(model_data, f, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    file_size = self._get_file_size(filepath)\n",
    "    print(f\"Model saved successfully to {filepath}\")\n",
    "    print(f\"Model size: {file_size:.2f} MB\")\n",
    "\n",
    "@staticmethod\n",
    "def load_model(filepath='models\\taglish_sentiment_model.pkl'):\n",
    "    \"\"\"Load a trained model from a pickle file\"\"\"\n",
    "    with open(filepath, 'rb') as f:\n",
    "        model_data = pickle.load(f)\n",
    "    \n",
    "    # Create new instance\n",
    "    analyzer = TaglishSentimentAnalyzer(\n",
    "        max_features=model_data['parameters']['max_features'],\n",
    "        ngram_range=model_data['parameters']['ngram_range'],\n",
    "        alpha=model_data['parameters']['alpha'],\n",
    "        pos_threshold=model_data['parameters']['pos_threshold'],\n",
    "        neg_threshold=model_data['parameters']['neg_threshold']\n",
    "    )\n",
    "    \n",
    "    # Restore trained components\n",
    "    analyzer.vectorizer = model_data['vectorizer']\n",
    "    analyzer.model = model_data['model']\n",
    "    analyzer.class_weights = model_data['class_weights']\n",
    "    analyzer.classes = model_data['classes']\n",
    "    analyzer.training_history = model_data['training_history']\n",
    "    analyzer.is_fitted = model_data['is_fitted']\n",
    "    \n",
    "    print(f\"ðŸ“‚ Model loaded successfully from {filepath}\")\n",
    "    if analyzer.training_history:\n",
    "        print(f\"   Training accuracy:  {analyzer.training_history['mean_accuracy']:.4f}\")\n",
    "        print(f\"   Training precision: {analyzer.training_history['mean_precision']:.4f}\")\n",
    "        print(f\"   Training recall:    {analyzer.training_history['mean_recall']:.4f}\")\n",
    "        print(f\"   Training F1-score:  {analyzer.training_history['mean_f1']:.4f}\")\n",
    "    \n",
    "    return analyzer\n",
    "\n",
    "def _get_file_size(self, filepath):\n",
    "    \"\"\"Get file size in MB\"\"\"\n",
    "    import os\n",
    "    return os.path.getsize(filepath) / (1024 * 1024)\n",
    "\n",
    "def get_model_info(self):\n",
    "    \"\"\"Get information about the trained model\"\"\"\n",
    "    if not self.is_fitted:\n",
    "        return \"Model not trained yet\"\n",
    "    \n",
    "    info = {\n",
    "        'is_trained': self.is_fitted,\n",
    "        'n_features': self.training_history.get('n_features', 'Unknown'),\n",
    "        'n_samples': self.training_history.get('n_samples', 'Unknown'),\n",
    "        'classes': self.classes.tolist() if self.classes is not None else [],\n",
    "        'class_weights': self.class_weights,\n",
    "        'mean_cv_accuracy': self.training_history.get('mean_accuracy', 'Unknown'),\n",
    "        'mean_cv_f1': self.training_history.get('mean_f1', 'Unknown'),\n",
    "        'parameters': {\n",
    "            'max_features': self.max_features,\n",
    "            'ngram_range': self.ngram_range,\n",
    "            'alpha': self.alpha,\n",
    "            'pos_threshold': self.pos_threshold,\n",
    "            'neg_threshold': self.neg_threshold\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return info\n",
    "\n",
    "TaglishSentimentAnalyzer.save_model = save_model\n",
    "TaglishSentimentAnalyzer.load_model = load_model\n",
    "TaglishSentimentAnalyzer._get_file_size = _get_file_size\n",
    "TaglishSentimentAnalyzer.get_model_info = get_model_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74b9e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_class_distribution(tweet_data):\n",
    "    \"\"\"Plot the distribution of sentiment classes\"\"\"\n",
    "    # Extract all clause sentiments\n",
    "    all_sentiments = []\n",
    "    for tweet in tweet_data:\n",
    "        for clause in tweet['clauses']:\n",
    "            all_sentiments.append(clause['sentiment'])\n",
    "    \n",
    "    # Count sentiments\n",
    "    sentiment_counts = Counter(all_sentiments)\n",
    "    \n",
    "    # Create plot\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1']\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    bars = plt.bar(sentiment_counts.keys(), sentiment_counts.values(), color=colors)\n",
    "    plt.title('Clause-level Sentiment Distribution')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{int(height)}',\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    # Pie chart\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.pie(sentiment_counts.values(), labels=sentiment_counts.keys(), \n",
    "            autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "    plt.title('Sentiment Distribution (%)')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return sentiment_counts\n",
    "\n",
    "def plot_training_results(training_history):\n",
    "    \"\"\"Plot cross-validation results\"\"\"\n",
    "    if not training_history or 'cv_results' not in training_history:\n",
    "        print(\"No training history available\")\n",
    "        return\n",
    "    \n",
    "    cv_results = training_history['cv_results']\n",
    "    \n",
    "    plt.figure(figsize=(12, 4))\n",
    "    \n",
    "    # Accuracy plot\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(cv_results['accuracy'], bins=15, alpha=0.7, color='#45b7d1', edgecolor='black')\n",
    "    plt.axvline(cv_results['accuracy'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {cv_results[\"accuracy\"].mean():.4f}')\n",
    "    plt.title('Cross-Validation Accuracy Distribution')\n",
    "    plt.xlabel('Accuracy')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    \n",
    "    # F1-score plot\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(cv_results['f1'], bins=15, alpha=0.7, color='#4ecdc4', edgecolor='black')\n",
    "    plt.axvline(cv_results['f1'].mean(), color='red', linestyle='--', \n",
    "                label=f'Mean: {cv_results[\"f1\"].mean():.4f}')\n",
    "    plt.title('Cross-Validation F1-Score Distribution')\n",
    "    plt.xlabel('F1-Score')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508a9856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_from_csv(csv_file_path, model_save_path='models\\taglish_sentiment_model.pkl', \n",
    "                         show_plots=True):\n",
    "\n",
    "    #Load data from CSV\n",
    "    tweet_data = load_data_from_csv(csv_file_path)\n",
    "    \n",
    "    #Data visualization\n",
    "    if show_plots:\n",
    "        print(\"\\nData Visualization:\")\n",
    "        sentiment_counts = plot_class_distribution(tweet_data)\n",
    "        print(\"Sentiment counts:\", sentiment_counts)\n",
    "    \n",
    "    #Initialization of model\n",
    "    print(\"\\nInitializing model...\")\n",
    "    analyzer = TaglishSentimentAnalyzer(\n",
    "        max_features=10000,\n",
    "        ngram_range=(1, 2),\n",
    "        alpha=1.0,\n",
    "        pos_threshold=0.2,\n",
    "        neg_threshold=-0.2\n",
    "    )\n",
    "    \n",
    "    #Train the model\n",
    "    training_results = analyzer.train(tweet_data, cv_folds=10, cv_repeats=10, verbose=True)\n",
    "    \n",
    "    #Show training results\n",
    "    if show_plots:\n",
    "        print(\"\\nTraining Results Visualization:\")\n",
    "        plot_training_results(training_results)\n",
    "    \n",
    "    #Save the model\n",
    "    analyzer.save_model(model_save_path)\n",
    "    \n",
    "    #Print summary\n",
    "    print(\"\\nTraining Summary:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Accuracy: {training_results['mean_accuracy']:.4f} Â± {training_results['std_accuracy']:.4f}\")\n",
    "    print(f\"F1-Score: {training_results['mean_f1']:.4f} Â± {training_results['std_f1']:.4f}\")\n",
    "    print(f\"Features: {training_results['n_features']}\")\n",
    "    print(f\"Samples: {training_results['n_samples']}\")\n",
    "    print(f\"Model saved to: {model_save_path}\")\n",
    "    \n",
    "    return analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5daf9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_from_csv_with_split(csv_file_path, test_size=0.1, random_state=42):\n",
    "    \"\"\"Load data from CSV and split into training and testing sets at the tweet level\"\"\"\n",
    "    \n",
    "    print(f\"Loading data from {csv_file_path}...\")\n",
    "    df = pd.read_csv(\n",
    "        csv_file_path,\n",
    "        skiprows=2, #skipping 2 rows \n",
    "        header=0,\n",
    "        names=[\"Tweet Number\", \"Clause Number\", \"Clause\", \"Final Sentiment\"]\n",
    "    )\n",
    "    \n",
    "    print(\"Columns found:\", df.columns.tolist())\n",
    "    print(\"First 5 rows:\")\n",
    "    print(df.head(5))\n",
    "\n",
    "    print(f\"Rows before cleaning: {len(df)}\")\n",
    "    missing_clause = df['Clause'].isna().sum()\n",
    "    missing_sentiment = df['Final Sentiment'].isna().sum()\n",
    "    print(f\"Rows with missing Clause: {missing_clause}\")\n",
    "    print(f\"Rows with missing Final Sentiment: {missing_sentiment}\")\n",
    "\n",
    "    # Clean data\n",
    "    df = df.dropna(subset=['Clause', 'Final Sentiment'])\n",
    "    print(f\"Rows after cleaning: {len(df)}\")\n",
    "\n",
    "    df['Clause'] = df['Clause'].astype(str).str.strip()\n",
    "    df['Final Sentiment'] = df['Final Sentiment'].astype(str).str.strip().str.lower()\n",
    "\n",
    "    print(f\"Loaded {len(df)} clauses from {df['Tweet Number'].nunique()} tweets\")\n",
    "    print(\"Sentiment distribution:\", df['Final Sentiment'].value_counts().to_dict())\n",
    "\n",
    "    # Convert to tweet structure\n",
    "    tweet_data = []\n",
    "    for tweet_num, tweet_group in df.groupby('Tweet Number'):\n",
    "        clauses = []\n",
    "        tweet_group = tweet_group.sort_values('Clause Number')\n",
    "        \n",
    "        # Collect all sentiments in this tweet for stratification\n",
    "        tweet_sentiments = tweet_group['Final Sentiment'].tolist()\n",
    "        \n",
    "        for _, row in tweet_group.iterrows():\n",
    "            clauses.append({\n",
    "                'clause_text': row['Clause'],\n",
    "                'sentiment': row['Final Sentiment']\n",
    "            })\n",
    "            \n",
    "        tweet_data.append({\n",
    "            'tweet_id': tweet_num,\n",
    "            'clauses': clauses,\n",
    "            'tweet_sentiments': tweet_sentiments\n",
    "        })\n",
    "\n",
    "    print(f\"Data conversion completed: {len(tweet_data)} tweets ready\")\n",
    "    \n",
    "    #TRAIN/TEST SPLIT\n",
    "    print(f\"\\nSplitting data: {int((1-test_size)*100)}% train, {int(test_size*100)}% test\")\n",
    "    \n",
    "    stratify_labels = []\n",
    "    for tweet in tweet_data:\n",
    "        sentiment_counts = Counter(tweet['tweet_sentiments'])\n",
    "        dominant_sentiment = sentiment_counts.most_common(1)[0][0]\n",
    "        stratify_labels.append(dominant_sentiment)\n",
    "    \n",
    "    print(\"Tweet-level sentiment distribution for stratification:\")\n",
    "    label_dist = Counter(stratify_labels)\n",
    "    print(label_dist)\n",
    "    \n",
    "    #Split tweets (not clauses) into train/test\n",
    "    train_tweets, test_tweets, train_labels, test_labels = train_test_split(\n",
    "        tweet_data,\n",
    "        stratify_labels,\n",
    "        test_size=test_size,\n",
    "        random_state=random_state,\n",
    "        stratify=stratify_labels  # Maintain sentiment distribution\n",
    "    )\n",
    "    \n",
    "    #Remove the temporary stratification field\n",
    "    for tweet in train_tweets + test_tweets:\n",
    "        tweet.pop('tweet_sentiments', None)\n",
    "    \n",
    "    #Calculate statistics\n",
    "    train_clauses = sum(len(tweet['clauses']) for tweet in train_tweets)\n",
    "    test_clauses = sum(len(tweet['clauses']) for tweet in test_tweets)\n",
    "    \n",
    "    #Get clause-level sentiment distributions\n",
    "    train_clause_sentiments = []\n",
    "    test_clause_sentiments = []\n",
    "    \n",
    "    for tweet in train_tweets:\n",
    "        for clause in tweet['clauses']:\n",
    "            train_clause_sentiments.append(clause['sentiment'])\n",
    "    \n",
    "    for tweet in test_tweets:\n",
    "        for clause in tweet['clauses']:\n",
    "            test_clause_sentiments.append(clause['sentiment'])\n",
    "    \n",
    "    train_sent_dist = Counter(train_clause_sentiments)\n",
    "    test_sent_dist = Counter(test_clause_sentiments)\n",
    "    \n",
    "    #Create summary info\n",
    "    data_info = {\n",
    "        'total_tweets': len(tweet_data),\n",
    "        'total_clauses': len(df),\n",
    "        'train_tweets': len(train_tweets),\n",
    "        'test_tweets': len(test_tweets),\n",
    "        'train_clauses': train_clauses,\n",
    "        'test_clauses': test_clauses,\n",
    "        'train_sentiment_dist': train_sent_dist,\n",
    "        'test_sentiment_dist': test_sent_dist,\n",
    "        'test_size_actual': len(test_tweets) / len(tweet_data)\n",
    "    }\n",
    "    \n",
    "    #Print split summary\n",
    "    print(f\"\\nSPLIT SUMMARY:\")\n",
    "    print(f\"{'='*50}\")\n",
    "    print(f\"TRAINING SET:\")\n",
    "    print(f\"Tweets: {data_info['train_tweets']:,} ({data_info['train_tweets']/data_info['total_tweets']*100:.1f}%)\")\n",
    "    print(f\"Clauses: {data_info['train_clauses']:,} ({data_info['train_clauses']/(data_info['train_clauses']+data_info['test_clauses'])*100:.1f}%)\")\n",
    "    print(f\"Sentiment distribution: {dict(train_sent_dist)}\")\n",
    "    \n",
    "    print(f\"\\nTESTING SET:\")\n",
    "    print(f\"Tweets: {data_info['test_tweets']:,} ({data_info['test_tweets']/data_info['total_tweets']*100:.1f}%)\")\n",
    "    print(f\"Clauses: {data_info['test_clauses']:,} ({data_info['test_clauses']/(data_info['train_clauses']+data_info['test_clauses'])*100:.1f}%)\")\n",
    "    print(f\"Sentiment distribution: {dict(test_sent_dist)}\")\n",
    "    \n",
    "    print(f\"\\nSplit completed successfully!\")\n",
    "    \n",
    "    return train_tweets, test_tweets, data_info\n",
    "\n",
    "def train_model_with_holdout_test(csv_file_path, \n",
    "                                  test_size=0.1, \n",
    "                                  model_save_path='models\\taglish_sentiment_model.pkl',\n",
    "                                  show_plots=True):\n",
    "    \"\"\"Complete pipeline with proper train/test split\"\"\"\n",
    "    \n",
    "    print(\"TRAINING WITH HOLDOUT TEST SET\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    #Load and split data\n",
    "    train_data, test_data, data_info = load_data_from_csv_with_split(\n",
    "        csv_file_path, test_size=test_size\n",
    "    )\n",
    "    \n",
    "    #Data visualization for training set\n",
    "    if show_plots:\n",
    "        print(\"\\nTraining Data Visualization:\")\n",
    "        plot_class_distribution(train_data)\n",
    "    \n",
    "    #Train model ONLY on training data\n",
    "    analyzer = TaglishSentimentAnalyzer(\n",
    "        max_features=10000,\n",
    "        ngram_range=(1, 2),\n",
    "        alpha=1.0,\n",
    "        pos_threshold=0.2,\n",
    "        neg_threshold=-0.2\n",
    "    )\n",
    "    \n",
    "    #Train with cross-validation on training data only\n",
    "    training_results = analyzer.train(train_data, cv_folds=10, cv_repeats=3, verbose=True)\n",
    "    \n",
    "    #Test on held-out test set\n",
    "    print(f\"\\nTESTING ON HELD-OUT TEST SET ({len(test_data)} tweets)\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    test_results = evaluate_on_test_set(analyzer, test_data)\n",
    "    \n",
    "    #Save model\n",
    "    analyzer.save_model(model_save_path)\n",
    "    \n",
    "    #Print final comparison\n",
    "    print(f\"\\nFINAL RESULTS COMPARISON:\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Cross-Validation (Training): {training_results['mean_accuracy']:.4f} Â± {training_results['std_accuracy']:.4f}\")\n",
    "    print(f\"Held-out Test Set:{test_results['accuracy']:.4f}\")\n",
    "    print(f\"Generalization Gap:{training_results['mean_accuracy'] - test_results['accuracy']:+.4f}\")\n",
    "    \n",
    "    if abs(training_results['mean_accuracy'] - test_results['accuracy']) < 0.05:\n",
    "        print(\"Model performs similarly on unseen data.\")\n",
    "    else:\n",
    "        print(\"Consider regularization or more data.\")\n",
    "    \n",
    "    return analyzer, test_results, data_info\n",
    "\n",
    "def evaluate_on_test_set(analyzer, test_data):\n",
    "    \"\"\"Evaluate trained model on held-out test set\"\"\"\n",
    "    \n",
    "    if not analyzer.is_fitted:\n",
    "        raise ValueError(\"Model must be trained before testing!\")\n",
    "    \n",
    "    # Prepare test data (same as training data preparation)\n",
    "    test_clause_df = analyzer.prepare_data(test_data)\n",
    "    \n",
    "    X_test_text = test_clause_df['clause_text'].tolist()\n",
    "    y_test = test_clause_df['sentiment'].values\n",
    "    \n",
    "    # Transform using the SAME vectorizer fitted on training data\n",
    "    X_test = analyzer.vectorizer.transform(X_test_text)\n",
    "    \n",
    "    # Predict on test set\n",
    "    y_pred = analyzer.model.predict(X_test)\n",
    "    y_pred_proba = analyzer.model.predict_proba(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    from sklearn.metrics import accuracy_score, precision_recall_fscore_support, classification_report\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    test_results = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1,\n",
    "        'n_test_clauses': len(y_test),\n",
    "        'n_test_tweets': len(test_data),\n",
    "        'classification_report': classification_report(y_test, y_pred),\n",
    "        'predictions': y_pred.tolist(),\n",
    "        'true_labels': y_test.tolist()\n",
    "    }\n",
    "    \n",
    "    print(f\"TEST SET PERFORMANCE:\")\n",
    "    print(f\"   Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"   Precision: {precision:.4f}\")\n",
    "    print(f\"   Recall:    {recall:.4f}\")\n",
    "    print(f\"   F1-Score:  {f1:.4f}\")\n",
    "    print(f\"   Test clauses: {len(y_test):,}\")\n",
    "    print(f\"   Test tweets: {len(test_data):,}\")\n",
    "    \n",
    "    print(f\"\\nDetailed Test Set Classification Report:\")\n",
    "    print(test_results['classification_report'])\n",
    "    \n",
    "    return test_results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"How to use:\")\n",
    "    print(\"Load and split data:\")\n",
    "    print(\"   train_data, test_data, info = load_data_from_csv_with_split('your_file.csv')\")\n",
    "    print()\n",
    "    print(\"Train with proper evaluation:\")\n",
    "    print(\"   analyzer, test_results, info = train_model_with_holdout_test('your_file.csv')\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108bc03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, split_info = load_data_from_csv_with_split(\"Final_Annotation.csv\", test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d9990c",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer, test_results, info = train_model_with_holdout_test('Final_Annotation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ce73b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test using unseen data, lagay ka lang ng random na tweet\n",
    "result1 = analyzer.predict_text(\"Grabe super panget ng pamumuno ng government ngayon at pano ba sila nabubuhay na alam nilang maraming namamatay na mamamamayan sa drug war nila?\")\n",
    "print(result1)\n",
    "\n",
    "result2 = analyzer.predict_text(\"\")\n",
    "print(result2)\n",
    "\n",
    "\n",
    "#Expected output\n",
    "#'text': '', (yung text na nilagay mo)\n",
    "#   'prediction': np.str_('positive/negative/neutral'), \n",
    "#   'probabilities': {np.str_('negative'): np.float64(0.3333333333333231), np.str_('neutral'): np.float64(0.33333333333329523), np.str_('positive'): np.float64(0.3333333333333817)}}\n",
    "#   Yung mga probabilities nakalista rito, kung ano yung confidence nila per class of sentiment, nakalagay sa float. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdc205",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarizarion lang nung accuracy, precision, recall, f1 score ng model\n",
    "loaded_analyzer = TaglishSentimentAnalyzer.load_model('models\\taglish_sentiment_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
